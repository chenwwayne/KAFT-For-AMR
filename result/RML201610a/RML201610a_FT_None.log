Using device: cuda

========================================
Running with parameters:
             dataset: RML201610a
           data_path: ./dataset
            n_epochs: 1000000000
            patience: 50
          batch_size: 400
  accumulation_steps: 1
          data_ratio: 1.0
                  lr: 0.001
         lr_patience: 5
           lr_factor: 0.5
              device: cuda
                 gpu: 0
========================================

Using GPU(s): 0
Using device: cuda
Namespace(dataset='RML201610a', data_path='./dataset', n_epochs=1000000000, patience=50, batch_size=400, accumulation_steps=1, data_ratio=1.0, lr=0.001, lr_patience=5, lr_factor=0.5, device='cuda', gpu='0')
Modulations: ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']
SNRs: [-20, -18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
Total samples: 220000
Padding: (132000, 128, 2)
Padding: (44000, 128, 2)
Padding: (44000, 128, 2)

Final data shapes:
X_train: (132000, 128, 2), Y_train: (132000, 11)
X_val: (44000, 128, 2), Y_val: (44000, 11)
X_test: (44000, 128, 2), Y_test: (44000, 11)
After reshaping and sampling:
X_train: (132000, 256) (sampled from original)
X_val:   (44000, 256) (sampled from original)
X_test:  (44000, 256) (sampled from original)
Y_train: (132000, 11)
{'d_out': 11, 'n_blocks': 3, 'd_block': 192, 'attention_n_heads': 8, 'attention_dropout': 0.2, 'ffn_d_hidden': None, 'ffn_d_hidden_multiplier': 1.3333333333333333, 'ffn_dropout': 0.1, 'residual_dropout': 0.0}
Model device: cuda:0
[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.
[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.
[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.
Total Parameters: 893.579K
FLOPs per sample: 209.493M
Device: CUDA
----------------------------------------------------------------------------------------

Epoch 0, Train Loss: 2.1504, Val Loss: 1.9714, Test Loss: 1.9720, Val Acc: 0.2478, Test Acc: 0.2480
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 1, Train Loss: 1.9282, Val Loss: 1.8952, Test Loss: 1.8940, Val Acc: 0.2701, Test Acc: 0.2715
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 2, Train Loss: 1.8367, Val Loss: 1.7697, Test Loss: 1.7677, Val Acc: 0.3159, Test Acc: 0.3179
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 3, Train Loss: 1.7472, Val Loss: 1.7217, Test Loss: 1.7182, Val Acc: 0.3397, Test Acc: 0.3414
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 4, Train Loss: 1.6995, Val Loss: 1.6494, Test Loss: 1.6482, Val Acc: 0.3605, Test Acc: 0.3608
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 5, Train Loss: 1.5962, Val Loss: 1.5170, Test Loss: 1.5150, Val Acc: 0.4297, Test Acc: 0.4312
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 6, Train Loss: 1.5025, Val Loss: 1.4599, Test Loss: 1.4577, Val Acc: 0.4517, Test Acc: 0.4539
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 7, Train Loss: 1.4402, Val Loss: 1.4271, Test Loss: 1.4273, Val Acc: 0.4602, Test Acc: 0.4608
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 8, Train Loss: 1.4022, Val Loss: 1.3854, Test Loss: 1.3855, Val Acc: 0.4818, Test Acc: 0.4804
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 9, Train Loss: 1.3786, Val Loss: 1.3700, Test Loss: 1.3723, Val Acc: 0.4847, Test Acc: 0.4837
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 10, Train Loss: 1.3615, Val Loss: 1.3465, Test Loss: 1.3453, Val Acc: 0.4927, Test Acc: 0.4925
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 11, Train Loss: 1.3497, Val Loss: 1.3527, Test Loss: 1.3487, Val Acc: 0.4932, Test Acc: 0.4949
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 12, Train Loss: 1.3388, Val Loss: 1.3400, Test Loss: 1.3383, Val Acc: 0.4955, Test Acc: 0.4962
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 13, Train Loss: 1.3244, Val Loss: 1.3271, Test Loss: 1.3303, Val Acc: 0.5013, Test Acc: 0.5012
ðŸŒ¸ New best epoch! ðŸŒ¸

Epoch 14, Train Loss: 1.3203, Val Loss: 1.3200, Test Loss: 1.3225, Val Acc: 0.5005, Test Acc: 0.5015

